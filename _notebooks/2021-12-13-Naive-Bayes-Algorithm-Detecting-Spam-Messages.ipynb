{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-revolution",
   "metadata": {},
   "source": [
    "# \"Naive Bayes Algorithm for Detecting Spam Messages\"\n",
    "\n",
    "> \"I code a multinomial naive bayes algorithm, step-by-step, in order to identify messages as spam or non-spam.\"\n",
    "\n",
    "- author: Migs Germar\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [python, pandas, numpy, matplotlib, seaborn, altair]\n",
    "- hide: true\n",
    "- search_exclude: true\n",
    "- image: images/spam-unsplash-hannes_johnson.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-prime",
   "metadata": {},
   "source": [
    "<center><img src = \"https://miguelahg.github.io/mahg-data-science/images/spam-unsplash-hannes_johnson.jpg\" alt = \"\"></center>\n",
    "\n",
    "<center><a href = \"https://unsplash.com/photos/mRgffV3Hc6c\">Unsplash | Hannes Johnson</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-valuable",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Multinomial Naive Bayes Algorithm is a machine learning algorithm based on the Bayes Theorem. It calculates the probability that an event $B$ occurred given that event $A$ occurred. Thus, it is usually used in classification problems. (Vadapalli, 2021)\n",
    "\n",
    "In this project, we will use the algorithm to determine the probability that a message is spam given its contents. We will then use this probability to decide whether to treat new messages as spam or not. For example, if the probability of being spam is over 50%, then we may treat the message as spam.\n",
    "\n",
    "Identifying spam is important in the Philippines because phishing campaigns went up by 200% after the pandemic began (Devanesan, 2020), and a telecommunications provider recently had to block around 71 million spam messages (Yap, 2021). Such messages may attempt to steal personal information, steal money from an account, or install malware (FTC, 2020). Thus, machine learning can be a very helpful tool in preventing such harm from occurring.\n",
    "\n",
    "Though the algorithm can be easily implemented using existing functions such as those in the [`scikit-learn` package](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes), I will manually code the algorithm step-by-step in order to explain the mathematical intuition behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-negotiation",
   "metadata": {},
   "source": [
    "> Note: I wrote this notebook by following a guided project on the [Dataquest](https://www.dataquest.io/) platform, specifically the [Guided Project: Building a Spam Filter with Naive Bayes](https://app.dataquest.io/c/74/m/433/guided-project%3A-building-a-spam-filter-with-naive-bayes/1/exploring-the-dataset) The general project flow came from Dataquest. The mathematical explanations are also based on what I learned from Dataquest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-challenge",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "\n",
    "Below are the packages necessary for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-twelve",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "We will use the SMS Spam Collection Dataset by Almeida and Hidalgo in 2012. It can be downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee9c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   sms     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sms_df = pd.read_csv(\n",
    "    \"./private/Naive-Bayes-Files/SMSSpamCollection\",\n",
    "    # Tab-separated\n",
    "    sep = \"\\t\",\n",
    "    header = None,\n",
    "    names = [\"label\", \"sms\"]\n",
    ")\n",
    "\n",
    "sms_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83348e4",
   "metadata": {},
   "source": [
    "The dataset has 2 columns and 5572 rows.\n",
    "\n",
    "- The `label` column contains \"ham\" if the message is legitimate, or \"spam\" if it is spam.\n",
    "- The `sms` column contains individual SMS messages.\n",
    "\n",
    "For example, below are the first 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0347763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794d4b3",
   "metadata": {},
   "source": [
    "# Training and Testing Sets\n",
    "\n",
    "The messages will be split into two sets. The training set, comprising 80% of the total data, will be used to train the Naive Bayes Algorithm. The testing set, with 20% of the total data, will be used to test the model's accuracy.\n",
    "\n",
    "First, however, let us calculate what percentage of the messages in the dataset are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "085c9eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam messages: 13.41%\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "spam_perc = sms_df[\"label\"].eq(\"spam\").sum() / sms_df.shape[0] * 100\n",
    "print(f\"Percentage of spam messages: {spam_perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d793148",
   "metadata": {},
   "source": [
    "Only 13% of the messages are spam. Therefore, spam and non-spam messages are not equally represented in this dataset, and this may be problematic. However, this is all the data we have, so the best we can do is to ensure that both the training and testing sets have around 13% of their messages as spam.\n",
    "\n",
    "This is an example of *proportional stratified sampling*. We first separate the data into two strata (spam and non-spam). We then take 80% of the messages from each strata as the training set. The remaining 20% of each strata is set aside for the testing set.\n",
    "\n",
    "This has been done with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc5e0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 4458\n",
      "Percentage of training messages that are spam: 13.41%\n",
      "Number of rows in testing set: 1114\n",
      "Percentage of testing messages that are spam: 13.38%\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "# Note: I could have used `train_test_split` from sklearn, but I coded this manually for the sake of grasping the logic.\n",
    "split_lists = {\n",
    "    \"training\": [],\n",
    "    \"testing\": [],\n",
    "}\n",
    "\n",
    "# Stratify the dataset\n",
    "for label in \"spam\", \"ham\":\n",
    "    stratum = sms_df.loc[sms_df[\"label\"] == label]\n",
    "\n",
    "    train_part = stratum.sample(\n",
    "        # Sample 80% of the data points\n",
    "        frac = 0.8,\n",
    "        random_state = 1,\n",
    "    )\n",
    "\n",
    "    # The other 20% that were not sampled go to the testing set.\n",
    "    test_part = stratum.loc[~stratum.index.isin(train_part.index)]\n",
    "\n",
    "    split_lists[\"training\"].append(train_part)\n",
    "    split_lists[\"testing\"].append(test_part)\n",
    "\n",
    "split_dfs = pd.Series(dtype = \"object\")\n",
    "for key in split_lists:\n",
    "    # Concatenate spam and non-spam parts into one DataFrame.\n",
    "    set_df = pd.concat(split_lists[key]).reset_index()\n",
    "    split_dfs[key] = set_df\n",
    "\n",
    "    perc_spam = set_df.label.eq('spam').sum() / set_df.shape[0] * 100\n",
    "\n",
    "    print(f\"Number of rows in {key} set: {set_df.shape[0]}\")\n",
    "    print(f\"Percentage of {key} messages that are spam: {perc_spam:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d4de6",
   "metadata": {},
   "source": [
    "We can see that the percentage of spam messages is roughly the same across the two sets. This will help the accuracy of the model later on.\n",
    "\n",
    "Now, the two sets will be further split into `X` and `y`. `y` refers to the **target**, or the variable that we are trying to predict. In this case, we are trying to predict whether a message is spam or non-spam, so the \"label\" column is the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b829d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ham\n",
       "1     ham\n",
       "2    spam\n",
       "3     ham\n",
       "4     ham\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sms_df.label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565535cc",
   "metadata": {},
   "source": [
    "On the other hand, `X` refers to the **features**, which are information used to predict the target. We only have one feature column as of now, which is the \"sms\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79d7bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4    Nah I don't think he goes to usf, he lives aro...\n",
       "Name: sms, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sms_df.sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7696d",
   "metadata": {},
   "source": [
    "\n",
    "Thus, we end up with four final objects:\n",
    "\n",
    "- `X_train`: The messages in the training data.\n",
    "- `X_test`: The messages in the testing data.\n",
    "- `y_train`: The labels in the training data. These correspond to `X_train`.\n",
    "- `y_test`: The labels in the testing data. These correspond to `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d351cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-show\n",
    "# The four objects listed above.\n",
    "X_train = split_dfs.training[[\"sms\"]]\n",
    "X_test = split_dfs.testing[[\"sms\"]]\n",
    "y_train = split_dfs.training[\"label\"]\n",
    "y_test = split_dfs.testing[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef021f4",
   "metadata": {},
   "source": [
    "# The Algorithm\n",
    "\n",
    "Now, let's discuss the multinomial naive bayes algorithm itself. As mentioned earlier, it is based on the Bayes Theorem. Given two events $A$ and $B$, we can use the theorem to determine the probability that $B$ happened given that $A$ happened. This probability is written as $P(B|A)$.\n",
    "\n",
    "$P(B|A) = \\frac{P(B) \\cdot P(A|B)}{\\Sigma_{i = 1}^n (P(B_i) \\cdot P(A|B_i))}$\n",
    "\n",
    "In this case, $B_1$ is the event that the message is non-spam, and $B_2$ is the event that it is spam. $B$ can refer to either $B_1$ or $B_2$, depending on which probability we want to calculate. Also, $A$ refers to the specific contents of one message.\n",
    "\n",
    "In order to make things clearer, let us say that $Spam$ is the event that the message is spam, and $Spam^C$ is the event that the message is non-spam.\n",
    "\n",
    "Then, let us expand event $A$ (the message itself) in order to consider the individual words inside it. For example, the first word in a message can be labeled $w_1$. If we have a total of $n$ words, then the words can be labeled as $w_1, w_2, \\dots , w_n$.\n",
    "\n",
    "Thus, we can rewrite the equation. Here is the probability of a given message being spam:\n",
    "\n",
    "$P(Spam|w_1, w_2, \\dots , w_n) = \\frac{P(Spam) \\cdot P(w_1, w_2, \\dots , w_n|Spam)}{\\Sigma_{i = 1}^n (P(B_i) \\cdot P(w_1, w_2, \\dots , w_n|B_i))}$\n",
    "\n",
    "Here is the probability of a given message being non-spam:\n",
    "\n",
    "$P(Spam^C|w_1, w_2, \\dots , w_n) = \\frac{P(Spam^C) \\cdot P(w_1, w_2, \\dots , w_n|Spam^C)}{\\Sigma_{i = 1}^n (P(B_i) \\cdot P(w_1, w_2, \\dots , w_n|B_i))}$\n",
    "\n",
    "Notice that the denominators are the same. Since we only want to compare these two probabilities, we can skip calculating the denominator and just calculate the numerators. We can thus rewrite the equation as follows. Note that the $\\propto$ symbol is used instead of $=$ because the two quantities are not equal but directly proportional.\n",
    "\n",
    "$P(Spam|w_1, w_2, \\dots , w_n) \\propto P(Spam) \\cdot P(w_1, w_2, \\dots , w_n|Spam)$\n",
    "\n",
    "The first factor, $P(Spam)$, is easy to find, as it is simply the number of spam messages divided by the total number of messages. However, $P(w_1, w_2, \\dots , w_n|Spam)$ needs to be further expanded.\n",
    "\n",
    "If we make the assumption that the probability of each word is independent of the probability of the other words, we can use the multiplication rule. The assumption of independence is what makes the algorithm \"naive,\" as it usually doesn't hold true in reality. However, the algorithm is still useful for predictions despite this.\n",
    "\n",
    "$P(Spam) \\cdot P(w_1, w_2, \\dots , w_n|Spam) \\\\ = P(Spam) \\cdot P(w_1 \\cap w_2 \\cap \\dots \\cap w_n | Spam) \\\\ = P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot \\dots \\cdot P(w_n|Spam)$\n",
    "\n",
    "Note that we still have to find the probability of each word given $Spam$ because we assume that the presence of each word is dependent on $Spam$.\n",
    "\n",
    "Thus, at this point, the final formula is:\n",
    "\n",
    "$P(Spam|w_1, w_2, \\dots , w_n) \\propto P(Spam) \\cdot \\Pi_{i=1}^n P(w_i|Spam)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
